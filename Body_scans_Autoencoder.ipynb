{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5524033-894f-47c5-b93a-1f745e8bfd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23a464cc-933f-41a4-ae87-62de6e10998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"/Users/negin/Desktop/UVA/Prof. Baek/result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b2bfec1-dacc-404a-879b-43067c97487c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2373</th>\n",
       "      <th>2374</th>\n",
       "      <th>2375</th>\n",
       "      <th>2376</th>\n",
       "      <th>2377</th>\n",
       "      <th>2378</th>\n",
       "      <th>2379</th>\n",
       "      <th>2380</th>\n",
       "      <th>2381</th>\n",
       "      <th>2382</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.031466</td>\n",
       "      <td>-0.039890</td>\n",
       "      <td>-0.035324</td>\n",
       "      <td>-0.047845</td>\n",
       "      <td>-0.045027</td>\n",
       "      <td>-0.038745</td>\n",
       "      <td>-0.043047</td>\n",
       "      <td>-0.027773</td>\n",
       "      <td>-0.036865</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034864</td>\n",
       "      <td>-0.042637</td>\n",
       "      <td>-0.040264</td>\n",
       "      <td>-0.035423</td>\n",
       "      <td>-0.056641</td>\n",
       "      <td>-0.035904</td>\n",
       "      <td>-0.042654</td>\n",
       "      <td>-0.040259</td>\n",
       "      <td>-0.032005</td>\n",
       "      <td>-0.032625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.862580</td>\n",
       "      <td>0.854115</td>\n",
       "      <td>0.817340</td>\n",
       "      <td>0.849635</td>\n",
       "      <td>0.830711</td>\n",
       "      <td>0.846198</td>\n",
       "      <td>0.801800</td>\n",
       "      <td>0.803400</td>\n",
       "      <td>0.727850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779687</td>\n",
       "      <td>0.754027</td>\n",
       "      <td>0.775268</td>\n",
       "      <td>0.826704</td>\n",
       "      <td>0.848708</td>\n",
       "      <td>0.842528</td>\n",
       "      <td>0.772226</td>\n",
       "      <td>0.795474</td>\n",
       "      <td>0.759403</td>\n",
       "      <td>0.753511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.052310</td>\n",
       "      <td>-0.050927</td>\n",
       "      <td>-0.058717</td>\n",
       "      <td>-0.087092</td>\n",
       "      <td>-0.066547</td>\n",
       "      <td>-0.087244</td>\n",
       "      <td>-0.066612</td>\n",
       "      <td>-0.054269</td>\n",
       "      <td>-0.067816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070726</td>\n",
       "      <td>-0.085786</td>\n",
       "      <td>-0.083504</td>\n",
       "      <td>-0.044417</td>\n",
       "      <td>-0.092971</td>\n",
       "      <td>-0.061990</td>\n",
       "      <td>-0.064521</td>\n",
       "      <td>-0.101571</td>\n",
       "      <td>-0.041343</td>\n",
       "      <td>-0.056151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.222086</td>\n",
       "      <td>-0.181017</td>\n",
       "      <td>-0.177770</td>\n",
       "      <td>-0.161982</td>\n",
       "      <td>-0.174208</td>\n",
       "      <td>-0.180938</td>\n",
       "      <td>-0.162400</td>\n",
       "      <td>-0.152754</td>\n",
       "      <td>-0.178659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160983</td>\n",
       "      <td>-0.178514</td>\n",
       "      <td>-0.182382</td>\n",
       "      <td>-0.180054</td>\n",
       "      <td>-0.160212</td>\n",
       "      <td>-0.156244</td>\n",
       "      <td>-0.161185</td>\n",
       "      <td>-0.166832</td>\n",
       "      <td>-0.162994</td>\n",
       "      <td>-0.133464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.053442</td>\n",
       "      <td>0.075136</td>\n",
       "      <td>0.066424</td>\n",
       "      <td>0.091687</td>\n",
       "      <td>0.075744</td>\n",
       "      <td>0.082278</td>\n",
       "      <td>0.070415</td>\n",
       "      <td>0.096938</td>\n",
       "      <td>0.084573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103820</td>\n",
       "      <td>0.062682</td>\n",
       "      <td>0.067893</td>\n",
       "      <td>0.063748</td>\n",
       "      <td>0.096304</td>\n",
       "      <td>0.091550</td>\n",
       "      <td>0.097243</td>\n",
       "      <td>0.091912</td>\n",
       "      <td>0.087170</td>\n",
       "      <td>0.094083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45529</th>\n",
       "      <td>45529</td>\n",
       "      <td>-0.461767</td>\n",
       "      <td>-0.416874</td>\n",
       "      <td>-0.407374</td>\n",
       "      <td>-0.398489</td>\n",
       "      <td>-0.397815</td>\n",
       "      <td>-0.420810</td>\n",
       "      <td>-0.393361</td>\n",
       "      <td>-0.365850</td>\n",
       "      <td>-0.367779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.348851</td>\n",
       "      <td>-0.378662</td>\n",
       "      <td>-0.405830</td>\n",
       "      <td>-0.431417</td>\n",
       "      <td>-0.389858</td>\n",
       "      <td>-0.390418</td>\n",
       "      <td>-0.358571</td>\n",
       "      <td>-0.380403</td>\n",
       "      <td>-0.368007</td>\n",
       "      <td>-0.339039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45530</th>\n",
       "      <td>45530</td>\n",
       "      <td>0.059079</td>\n",
       "      <td>0.052843</td>\n",
       "      <td>0.050383</td>\n",
       "      <td>0.013790</td>\n",
       "      <td>0.040163</td>\n",
       "      <td>0.061034</td>\n",
       "      <td>0.019664</td>\n",
       "      <td>0.027637</td>\n",
       "      <td>0.048154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035062</td>\n",
       "      <td>0.026391</td>\n",
       "      <td>0.019918</td>\n",
       "      <td>0.068048</td>\n",
       "      <td>0.040033</td>\n",
       "      <td>0.061636</td>\n",
       "      <td>0.026033</td>\n",
       "      <td>0.057075</td>\n",
       "      <td>0.030242</td>\n",
       "      <td>0.023261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45531</th>\n",
       "      <td>45531</td>\n",
       "      <td>0.171571</td>\n",
       "      <td>0.166229</td>\n",
       "      <td>0.145535</td>\n",
       "      <td>0.135030</td>\n",
       "      <td>0.159251</td>\n",
       "      <td>0.135231</td>\n",
       "      <td>0.130648</td>\n",
       "      <td>0.143890</td>\n",
       "      <td>0.148878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125137</td>\n",
       "      <td>0.139102</td>\n",
       "      <td>0.151415</td>\n",
       "      <td>0.141220</td>\n",
       "      <td>0.136947</td>\n",
       "      <td>0.144266</td>\n",
       "      <td>0.142527</td>\n",
       "      <td>0.130889</td>\n",
       "      <td>0.144135</td>\n",
       "      <td>0.137630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45532</th>\n",
       "      <td>45532</td>\n",
       "      <td>-0.450008</td>\n",
       "      <td>-0.406368</td>\n",
       "      <td>-0.398377</td>\n",
       "      <td>-0.388785</td>\n",
       "      <td>-0.387637</td>\n",
       "      <td>-0.409573</td>\n",
       "      <td>-0.384977</td>\n",
       "      <td>-0.357979</td>\n",
       "      <td>-0.358463</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.341991</td>\n",
       "      <td>-0.366590</td>\n",
       "      <td>-0.393265</td>\n",
       "      <td>-0.420757</td>\n",
       "      <td>-0.380272</td>\n",
       "      <td>-0.379364</td>\n",
       "      <td>-0.350444</td>\n",
       "      <td>-0.370129</td>\n",
       "      <td>-0.361422</td>\n",
       "      <td>-0.331536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45533</th>\n",
       "      <td>45533</td>\n",
       "      <td>-0.012297</td>\n",
       "      <td>-0.020171</td>\n",
       "      <td>-0.012640</td>\n",
       "      <td>-0.053489</td>\n",
       "      <td>-0.029927</td>\n",
       "      <td>-0.012437</td>\n",
       "      <td>-0.041869</td>\n",
       "      <td>-0.031290</td>\n",
       "      <td>-0.016305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019541</td>\n",
       "      <td>-0.041607</td>\n",
       "      <td>-0.050557</td>\n",
       "      <td>-0.002102</td>\n",
       "      <td>-0.028576</td>\n",
       "      <td>-0.011325</td>\n",
       "      <td>-0.038169</td>\n",
       "      <td>-0.012815</td>\n",
       "      <td>-0.024916</td>\n",
       "      <td>-0.033612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45534 rows Ã— 2384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0               0 -0.031466 -0.039890 -0.035324 -0.047845 -0.045027 -0.038745   \n",
       "1               1  0.862580  0.854115  0.817340  0.849635  0.830711  0.846198   \n",
       "2               2 -0.052310 -0.050927 -0.058717 -0.087092 -0.066547 -0.087244   \n",
       "3               3 -0.222086 -0.181017 -0.177770 -0.161982 -0.174208 -0.180938   \n",
       "4               4  0.053442  0.075136  0.066424  0.091687  0.075744  0.082278   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "45529       45529 -0.461767 -0.416874 -0.407374 -0.398489 -0.397815 -0.420810   \n",
       "45530       45530  0.059079  0.052843  0.050383  0.013790  0.040163  0.061034   \n",
       "45531       45531  0.171571  0.166229  0.145535  0.135030  0.159251  0.135231   \n",
       "45532       45532 -0.450008 -0.406368 -0.398377 -0.388785 -0.387637 -0.409573   \n",
       "45533       45533 -0.012297 -0.020171 -0.012640 -0.053489 -0.029927 -0.012437   \n",
       "\n",
       "              6         7         8  ...      2373      2374      2375  \\\n",
       "0     -0.043047 -0.027773 -0.036865  ... -0.034864 -0.042637 -0.040264   \n",
       "1      0.801800  0.803400  0.727850  ...  0.779687  0.754027  0.775268   \n",
       "2     -0.066612 -0.054269 -0.067816  ... -0.070726 -0.085786 -0.083504   \n",
       "3     -0.162400 -0.152754 -0.178659  ... -0.160983 -0.178514 -0.182382   \n",
       "4      0.070415  0.096938  0.084573  ...  0.103820  0.062682  0.067893   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "45529 -0.393361 -0.365850 -0.367779  ... -0.348851 -0.378662 -0.405830   \n",
       "45530  0.019664  0.027637  0.048154  ...  0.035062  0.026391  0.019918   \n",
       "45531  0.130648  0.143890  0.148878  ...  0.125137  0.139102  0.151415   \n",
       "45532 -0.384977 -0.357979 -0.358463  ... -0.341991 -0.366590 -0.393265   \n",
       "45533 -0.041869 -0.031290 -0.016305  ... -0.019541 -0.041607 -0.050557   \n",
       "\n",
       "           2376      2377      2378      2379      2380      2381      2382  \n",
       "0     -0.035423 -0.056641 -0.035904 -0.042654 -0.040259 -0.032005 -0.032625  \n",
       "1      0.826704  0.848708  0.842528  0.772226  0.795474  0.759403  0.753511  \n",
       "2     -0.044417 -0.092971 -0.061990 -0.064521 -0.101571 -0.041343 -0.056151  \n",
       "3     -0.180054 -0.160212 -0.156244 -0.161185 -0.166832 -0.162994 -0.133464  \n",
       "4      0.063748  0.096304  0.091550  0.097243  0.091912  0.087170  0.094083  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "45529 -0.431417 -0.389858 -0.390418 -0.358571 -0.380403 -0.368007 -0.339039  \n",
       "45530  0.068048  0.040033  0.061636  0.026033  0.057075  0.030242  0.023261  \n",
       "45531  0.141220  0.136947  0.144266  0.142527  0.130889  0.144135  0.137630  \n",
       "45532 -0.420757 -0.380272 -0.379364 -0.350444 -0.370129 -0.361422 -0.331536  \n",
       "45533 -0.002102 -0.028576 -0.011325 -0.038169 -0.012815 -0.024916 -0.033612  \n",
       "\n",
       "[45534 rows x 2384 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9104547b-976a-4136-8ac0-284e4497ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "514dc608-87a2-4d97-b9e3-1fd3110cfa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data to have zero mean and unit variance\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "193487c8-8231-4317-8f75-4add0d03f032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45534, 2384)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36c54028-9405-401d-8abb-e7e044ec73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This is the dimension of the original space\n",
    "input_dim = 2384\n",
    "\n",
    "# This is the dimension of the latent space (encoding space)\n",
    "latent_dim = 14\n",
    "\n",
    "encoder = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(latent_dim, activation='relu')\n",
    "])\n",
    "\n",
    "decoder = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(latent_dim,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(input_dim, activation=None)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1dae1a2-a2a4-43ef-bb2c-d355d986ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stitch up the encoder and the decoder models into a single model, the autoencoder.\n",
    "\n",
    "autoencoder = Model(inputs=encoder.input, outputs=decoder(encoder.output))\n",
    "autoencoder.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca04ec8e-3beb-4fbb-8fa2-c1fdfcbf5bca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def plot_orig_vs_recon(title='', n_samples=3):\n",
    "#     fig = plt.figure(figsize=(2384,6))\n",
    "#     plt.suptitle(title)\n",
    "#     for i in range(3):\n",
    "#         plt.subplot(3, 1, i+1)\n",
    "#         idx = random.sample(range(x_train.shape[0]), 1)\n",
    "#         plt.plot(autoencoder.predict(x_train[idx]).squeeze(), label='reconstructed' if i == 0 else '')\n",
    "#         plt.plot(x_train[idx].squeeze(), label='original' if i == 0 else '')\n",
    "#         fig.axes[i].set_xticklabels(metric_names)\n",
    "#         plt.xticks(np.arange(0, 2382, 1))\n",
    "#         plt.grid(True)\n",
    "#         if i == 0: plt.legend();\n",
    "\n",
    "# plot_orig_vs_recon('Before training the encoder-decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b0b94-0b42-486d-8335-2c4bbda996ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = autoencoder.fit(x_train, x_train, epochs=60, batch_size=32, verbose=0)\n",
    "\n",
    "plt.plot(model_history.history[\"loss\"])\n",
    "plt.title(\"Loss vs. Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77768b18-364e-4d48-88ff-2355e79a2bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_orig_vs_recon('After training the encoder-decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c5385-1332-473f-8e6e-e09bc69bc09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_x_train = encoder(x_train)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(encoded_x_train[:, 0], encoded_x_train[:, 1], alpha=.8)\n",
    "plt.xlabel('Latent Dimension 1')\n",
    "plt.ylabel('Latent Dimension 2');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
